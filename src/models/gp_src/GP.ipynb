{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404495b6-090d-414c-8270-1aeece9a29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import pathlib\n",
    "from typing import Type\n",
    "from datetime import  datetime\n",
    "import os\n",
    "#from croston import croston\n",
    "# from timeseries.models.deepar import DeepAR\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gpflow import default_float\n",
    "from gpflow.kernels import Kernel\n",
    "from gpflow.likelihoods import Likelihood\n",
    "from timeseries.errors import compute_errors\n",
    "from timeseries.likelihoods import NegativeBinomial\n",
    "from timeseries.models.gaussian_process import GaussianProcess\n",
    "from timeseries.models.kernels import Kernel_Comb3#, Kernel_Comb1, Kernel_Comb2, MaternTimeseriesKernel\n",
    "from timeseries.timeseries import Timeseries\n",
    "def get_kernel(kernel) -> Type[Kernel]:\n",
    "    if kernel == \"Kernel_Comb3\":\n",
    "        return Kernel_Comb3\n",
    "    # if kernel == \"Kernel_Comb1\":\n",
    "    #     return Kernel_Comb1\n",
    "    # if kernel == \"Kernel_Comb2\":\n",
    "    #     return Kernel_Comb2\n",
    "    # if kernel == \"Matern\":\n",
    "        # return MaternTimeseriesKernel\n",
    "    raise ValueError(\"wrong kernel specified\")\n",
    "\n",
    "\n",
    "def get_likelihood(likelihood) -> Type[Likelihood]:\n",
    "    if likelihood == \"NB\":\n",
    "        return NegativeBinomial\n",
    "    raise ValueError(\"wrong kernel specified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8302b8-cd35-47c2-9662-ffa8dd59e70c",
   "metadata": {},
   "source": [
    "### GP method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b71636-c608-470f-b594-1e9c87c5275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_fit_forecast(x_train, x_test, y_train, y_test, prediction_length,\n",
    "                    kernel='Kernel_Comb3', likelihood='NB', num_restarts=3, use_priors=True):\n",
    "    \n",
    "    m = GaussianProcess(kernel=get_kernel(kernel),\n",
    "                        likelihood=get_likelihood(likelihood),use_priors=use_priors)\n",
    "    \n",
    "    elboopt = -np.inf\n",
    "    for i in range(num_restarts):\n",
    "        m.fit(y_train, x_train,\n",
    "                  prediction_length=h, iterations=5000, n_batch=256)\n",
    "        elbo = np.array(m._model.elbo((x_train,y_train)))\n",
    "        if elboopt<elbo:\n",
    "            elboopt=elbo\n",
    "    \n",
    "    return m.forecast(y_test, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c753c-be17-453b-97a3-2e0dfef3f789",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare and create a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7bdc3e-cc90-4e0c-9169-cb6da2ba7c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DP = '../../../data/'\n",
    "MP = '../../../models/'\n",
    "ste = pd.read_pickle(f'{_DP}processed/sales_train_evaluation.pkl')\n",
    "x = np.load(f'{_DP}processed/time_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df701f89-5659-4747-b3c8-02b973ac8b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_ids = np.load(f'{_DP}interim/sampled_ids.npy').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fad7aa-877b-48c8-b0ed-1e44948963f9",
   "metadata": {},
   "source": [
    "# -------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19c7e4c-b21e-4e9b-9d31-bba2b95a156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_ste = \\\n",
    "    ste \\\n",
    "    .reset_index('id') \\\n",
    "    .reset_index() \\\n",
    "    .set_index('id') \\\n",
    "    .loc[sampled_ids] \\\n",
    "    .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f70210-40ba-4aa3-9d27-b6f268afefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_y = sampled_ste.set_index('id') \\\n",
    "    .iloc[:, 1:] \\\n",
    "    .astype('float64') \\\n",
    "    .to_numpy() \\\n",
    "    .transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea015d6-4fdc-46a1-948e-e8ebfcba57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = sampled_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d809c-3eca-405f-8d1b-8fed0f5bbd30",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9b406d9-c241-4d09-a635-91d78a4b9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_name = 'GP_305'\n",
    "DP = MP\n",
    "model_path = f'{DP}{m_name}/'\n",
    "os.makedirs(model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c9972-67ba-4920-8c56-d32346dca179",
   "metadata": {},
   "source": [
    "Run the following cell only once, then comment out if you continue the code another time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2c874a0-c9b2-4855-86d0-9dd2e1b3f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 355 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction_length = 28\n",
    "################################ NOTE: ########################################\n",
    "# n_ys is hard coded here AND in gaussian_process.py. If you change #\n",
    "# its numerical value here, make sure to change it in gaussian_process.py too #\n",
    "###############################################################################\n",
    "n_ys = 500\n",
    "\n",
    "remaining_IDs = np.arange(all_y.shape[1])\n",
    "\n",
    "pred_shape = (prediction_length, all_y.shape[1])\n",
    "pmf_pred_shape = (n_ys, prediction_length, all_y.shape[1])\n",
    "means = -1 * np.ones(pred_shape)\n",
    "variances = -1 * np.ones(pred_shape)\n",
    "pmfs = -1 * np.ones(pmf_pred_shape)\n",
    "\n",
    "np.save(f'{model_path}remaining_IDs.npy', remaining_IDs)\n",
    "np.save(f'{model_path}means.npy', means)\n",
    "np.save(f'{model_path}variances.npy', variances)\n",
    "np.save(f'{model_path}pmfs.npy', pmfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93c6ddcd-02c1-467c-aa71-f224f479c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.load(f'{model_path}means.npy')\n",
    "variances = np.load(f'{model_path}variances.npy')\n",
    "remaining_IDs = np.load(f'{model_path}remaining_IDs.npy')\n",
    "pmfs = np.load(f'{model_path}pmfs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ab829e1-9bdb-4508-b291-9af57576dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46391c9e-722d-429a-bb24-fe573af6c377",
   "metadata": {},
   "source": [
    "To start forecasting, run the following cell:\n",
    "\n",
    "Once you want to turn off the script and save the preliminary results before all forecasts are completed, interrup the kernel (`I`+`I` keyboard shortcut), and run the two cells following this cell. To continue forecasting, simply re run this notebook, skipping the cell which initialised means, variances, pmfs, remaining_IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7058179e-c30c-44bb-8a3f-0187c8a0a8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "RUNNING THE GP_305 METHOD:\n",
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\stats\\_discrete_distns.py:307: RuntimeWarning: divide by zero encountered in _nbinom_pdf\n",
      "  return _boost._nbinom_pdf(x, n, p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished forecasting sales for all items up to (inclusive) item 0\n",
      "Finished forecasting sales for all items up to (inclusive) item 5\n",
      "Finished forecasting sales for all items up to (inclusive) item 10\n",
      "Finished forecasting sales for all items up to (inclusive) item 15\n",
      "Finished forecasting sales for all items up to (inclusive) item 20\n",
      "Finished forecasting sales for all items up to (inclusive) item 25\n",
      "Finished forecasting sales for all items up to (inclusive) item 30\n",
      "Finished forecasting sales for all items up to (inclusive) item 35\n",
      "Finished forecasting sales for all items up to (inclusive) item 40\n",
      "Finished forecasting sales for all items up to (inclusive) item 45\n",
      "########################################\n",
      "50 more forecasts completed. Saving means, variances, pmfs, and new_remaining_IDs.\n",
      "255 forecasts left.\n",
      "Script has been running for 26.0 minutes.\n",
      "########################################\n",
      "Finished forecasting sales for all items up to (inclusive) item 50\n",
      "Finished forecasting sales for all items up to (inclusive) item 55\n",
      "Finished forecasting sales for all items up to (inclusive) item 60\n",
      "Finished forecasting sales for all items up to (inclusive) item 65\n",
      "Finished forecasting sales for all items up to (inclusive) item 70\n",
      "Finished forecasting sales for all items up to (inclusive) item 75\n",
      "Finished forecasting sales for all items up to (inclusive) item 80\n",
      "Finished forecasting sales for all items up to (inclusive) item 85\n",
      "Finished forecasting sales for all items up to (inclusive) item 90\n",
      "Finished forecasting sales for all items up to (inclusive) item 95\n",
      "########################################\n",
      "50 more forecasts completed. Saving means, variances, pmfs, and new_remaining_IDs.\n",
      "205 forecasts left.\n",
      "Script has been running for 53.0 minutes.\n",
      "########################################\n",
      "Finished forecasting sales for all items up to (inclusive) item 100\n",
      "Finished forecasting sales for all items up to (inclusive) item 105\n",
      "Finished forecasting sales for all items up to (inclusive) item 110\n",
      "Finished forecasting sales for all items up to (inclusive) item 115\n",
      "Finished forecasting sales for all items up to (inclusive) item 120\n",
      "Finished forecasting sales for all items up to (inclusive) item 125\n",
      "Finished forecasting sales for all items up to (inclusive) item 130\n",
      "Finished forecasting sales for all items up to (inclusive) item 135\n",
      "Finished forecasting sales for all items up to (inclusive) item 140\n",
      "Finished forecasting sales for all items up to (inclusive) item 145\n",
      "########################################\n",
      "50 more forecasts completed. Saving means, variances, pmfs, and new_remaining_IDs.\n",
      "155 forecasts left.\n",
      "Script has been running for 79.0 minutes.\n",
      "########################################\n",
      "Finished forecasting sales for all items up to (inclusive) item 150\n",
      "Finished forecasting sales for all items up to (inclusive) item 155\n",
      "Finished forecasting sales for all items up to (inclusive) item 160\n",
      "Finished forecasting sales for all items up to (inclusive) item 165\n",
      "Finished forecasting sales for all items up to (inclusive) item 170\n",
      "Finished forecasting sales for all items up to (inclusive) item 175\n",
      "Finished forecasting sales for all items up to (inclusive) item 180\n",
      "Finished forecasting sales for all items up to (inclusive) item 185\n",
      "Finished forecasting sales for all items up to (inclusive) item 190\n",
      "Finished forecasting sales for all items up to (inclusive) item 195\n",
      "########################################\n",
      "50 more forecasts completed. Saving means, variances, pmfs, and new_remaining_IDs.\n",
      "105 forecasts left.\n",
      "Script has been running for 105.0 minutes.\n",
      "########################################\n",
      "Finished forecasting sales for all items up to (inclusive) item 200\n",
      "Finished forecasting sales for all items up to (inclusive) item 205\n",
      "Finished forecasting sales for all items up to (inclusive) item 210\n",
      "Finished forecasting sales for all items up to (inclusive) item 215\n",
      "Finished forecasting sales for all items up to (inclusive) item 220\n",
      "Finished forecasting sales for all items up to (inclusive) item 225\n",
      "Finished forecasting sales for all items up to (inclusive) item 230\n",
      "Finished forecasting sales for all items up to (inclusive) item 235\n",
      "Finished forecasting sales for all items up to (inclusive) item 240\n",
      "Finished forecasting sales for all items up to (inclusive) item 245\n",
      "########################################\n",
      "50 more forecasts completed. Saving means, variances, pmfs, and new_remaining_IDs.\n",
      "55 forecasts left.\n",
      "Script has been running for 132.0 minutes.\n",
      "########################################\n",
      "Finished forecasting sales for all items up to (inclusive) item 250\n",
      "Finished forecasting sales for all items up to (inclusive) item 255\n",
      "Finished forecasting sales for all items up to (inclusive) item 260\n",
      "Finished forecasting sales for all items up to (inclusive) item 265\n",
      "Finished forecasting sales for all items up to (inclusive) item 270\n",
      "Finished forecasting sales for all items up to (inclusive) item 275\n",
      "Finished forecasting sales for all items up to (inclusive) item 280\n",
      "Finished forecasting sales for all items up to (inclusive) item 285\n",
      "Finished forecasting sales for all items up to (inclusive) item 290\n",
      "Finished forecasting sales for all items up to (inclusive) item 295\n",
      "########################################\n",
      "50 more forecasts completed. Saving means, variances, pmfs, and new_remaining_IDs.\n",
      "5 forecasts left.\n",
      "Script has been running for 158.0 minutes.\n",
      "########################################\n",
      "Finished forecasting sales for all items up to (inclusive) item 300\n",
      "Wall time: 2h 40min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print_interval = 5\n",
    "save_interval = 50\n",
    "\n",
    "prediction_length = 28\n",
    "h = prediction_length\n",
    "# commented these out since we are not comparing to SkewGP anymore, so no need to include only the last 250 time steps\n",
    "# ncut = 1913\n",
    "# ncut = 250\n",
    "# ncutph = ncut + h\n",
    "ncutph = all_y.shape[0]\n",
    "x_train, x_test = x[-ncutph:-h], x[-h:]\n",
    "start = time.perf_counter()\n",
    "print('#'*40)\n",
    "print(f'RUNNING THE {m_name} METHOD:')\n",
    "print('#'*40)\n",
    "for i, ID in enumerate(remaining_IDs):\n",
    "    ind_nz = ncutph - np.where(all_y[-ncutph:,ID]>0)[0][0]\n",
    "    ncutph0 = np.minimum(ncutph,ind_nz)\n",
    "    y_train = all_y[-ncutph0:-h, ID][:, np.newaxis]\n",
    "    y_test = all_y[-h:, ID][:, np.newaxis]\n",
    "    x_train_temp = x[-ncutph0:-h][:]\n",
    "\n",
    "    y_hat, y_hat_var, y_pmf = GP_fit_forecast(x_train_temp, x_test, y_train, y_test, h, num_restarts=3)#, kernel='Kernel_Comb1')\n",
    "\n",
    "    \n",
    "    means[:, ID][:, np.newaxis] = y_hat\n",
    "    variances[:, ID][:, np.newaxis] = y_hat_var\n",
    "    pmfs[:, :, ID][:, :, np.newaxis] = y_pmf\n",
    "\n",
    "    last_idx = i\n",
    "    if ID % print_interval == 0:\n",
    "        print(f'Finished forecasting sales for all items up to (inclusive) item {ID}')\n",
    "    \n",
    "    if (i + 1) % save_interval == 0:\n",
    "        np.save(f'{model_path}means.npy', means)\n",
    "        np.save(f'{model_path}variances.npy', variances)\n",
    "        np.save(f'{model_path}pmfs.npy', pmfs)\n",
    "        temp_new_remaining_IDs = remaining_IDs[i+1:]\n",
    "        np.save(f'{model_path}remaining_IDs.npy', temp_new_remaining_IDs)\n",
    "        \n",
    "        print('#' * 40)\n",
    "        print(f'{save_interval} more forecasts completed. Saving means, variances, pmfs, and new_remaining_IDs.')\n",
    "        print(f'{len(temp_new_remaining_IDs)} forecasts left.')\n",
    "        temp_end = time.perf_counter()\n",
    "        print(f'Script has been running for {np.round((temp_end - start)/60, 0)} minutes.')\n",
    "        print('#' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ca4bfed-a224-451d-856a-85d793b80e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158d131c-4dee-429c-87d2-b566e1f620c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started with 305 time series to forecast, now left with 0 time series to forecast. In total, 305 time series' have been forecasted\n",
      "\n",
      "Forecasting these 305 time series' took about 9652 seconds , or 31.64 seconds per time series.\n",
      "\n",
      "If this speed were to continue, it would take 0.00 hours to forecast the rest of the time series'\n"
     ]
    }
   ],
   "source": [
    "new_remaining_IDs = remaining_IDs[last_idx+1:]\n",
    "total_time = end - start\n",
    "tss_forecasted = len(remaining_IDs) - len(new_remaining_IDs)\n",
    "time_per_ts = total_time / tss_forecasted\n",
    "\n",
    "print(f'Started with {len(remaining_IDs)} time series to forecast,',\n",
    "      f'now left with {len(new_remaining_IDs)} time series to forecast. In total, {305-len(new_remaining_IDs)}',\n",
    "      f\"time series' have been forecasted\")\n",
    "print()\n",
    "print(f\"Forecasting these {tss_forecasted} time series' took about {total_time:.0f} seconds\",\n",
    "     f', or {time_per_ts:.2f} seconds per time series.') \n",
    "print()\n",
    "print(f'If this speed were to continue, it would',\n",
    "     f'take {(time_per_ts * len(new_remaining_IDs)) / 3600 :.2f} hours to forecast the rest of the',\n",
    "     f\"time series'\")\n",
    "\n",
    "np.save(f'{model_path}remaining_IDs.npy', new_remaining_IDs)\n",
    "np.save(f'{model_path}means.npy', means)\n",
    "np.save(f'{model_path}variances.npy', variances)\n",
    "np.save(f'{model_path}pmfs.npy', pmfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af817cf-c41f-478c-907b-11f9c6bf80ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10228911, 0.10285551, 0.10345286, ..., 0.12237464, 0.12332276,\n",
       "        0.12426703],\n",
       "       [0.17304491, 0.17392735, 0.17485787, ..., 0.20389801, 0.2053304 ,\n",
       "        0.20675317],\n",
       "       [0.23099044, 0.23207474, 0.2332182 , ..., 0.26848702, 0.27020521,\n",
       "        0.27190803],\n",
       "       ...,\n",
       "       [0.99177307, 0.99138946, 0.99100096, ..., 0.98365207, 0.983427  ,\n",
       "        0.98320468],\n",
       "       [0.99194477, 0.9915657 , 0.99118162, ..., 0.98388999, 0.98366568,\n",
       "        0.98344407],\n",
       "       [0.99211239, 0.9917378 , 0.9913581 , ..., 0.98412349, 0.98389995,\n",
       "        0.98367905]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def pmf_to_cmf(pmfs):\n",
    "#     cmfs = -1 * np.ones(pmfs.shape)\n",
    "#     cmfs[0] = pmfs[0]\n",
    "#     for y in range(1, pmfs.shape[0]):\n",
    "#         cmfs[y] = cmfs[y-1] + pmfs[y]\n",
    "#     return cmfs\n",
    "\n",
    "# pmf_to_cmf(pmfs[:, :, 68])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
